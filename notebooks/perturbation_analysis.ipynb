{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fb47ab-c8ac-4dc6-a473-cad346be20b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32652b1-d162-46a7-beba-b0df68df85e1",
   "metadata": {},
   "source": [
    "# Performing perturbation analysis on NLP datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089dd6d7-bedb-49dc-94f0-4109d0c83783",
   "metadata": {},
   "source": [
    "## Load model and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2d6579-5e51-4228-9c84-3b29ca5af699",
   "metadata": {},
   "outputs": [],
   "source": [
    "from symbxai.lrp.symbolic_xai import BERTSymbXAI, ViTSymbolicXAI\n",
    "from symbxai.model.transformer import bert_base_uncased_model\n",
    "from symbxai.dataset.utils import load_sst_treebank, load_imdb_dataset\n",
    "import transformers\n",
    "\n",
    "\n",
    "sample_range = [1]\n",
    "data_mode = 'sst'\n",
    "\n",
    "if data_mode == 'sst': # Load SST data and model\n",
    "    model = bert_base_uncased_model(\n",
    "            pretrained_model_name_or_path='textattack/bert-base-uncased-SST-2' )\n",
    "    \n",
    "    model.eval()\n",
    "    # pretrained_embeddings = model.bert.embeddings\n",
    "    tokenizer = transformers.BertTokenizer.from_pretrained(\"textattack/bert-base-uncased-SST-2\")\n",
    "    \n",
    "    dataset = load_sst_treebank(sample_range, verbose=False)['train']\n",
    "    print('got', len(dataset['label']), 'samples from sst')\n",
    "    input_type = 'sentence'\n",
    "elif data_mode == 'imdb': # Load IMDB data and model\n",
    "    # Load the dataset\n",
    "    dataset = load_imdb_dataset(sample_range)\n",
    "\n",
    "    # Load the model and tokenizer\n",
    "    model = bert_base_uncased_model(\n",
    "            pretrained_model_name_or_path='textattack/bert-base-uncased-imdb' )\n",
    "    \n",
    "    model.eval()\n",
    "    # pretrained_embeddings = model.bert.embeddings\n",
    "    tokenizer = transformers.BertTokenizer.from_pretrained(\"textattack/bert-base-uncased-imdb\")\n",
    "    input_type = 'sentence'\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612bf17e-2a91-49f2-ada1-5762ff133f66",
   "metadata": {},
   "source": [
    "## Define perturbation order by XAI method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6603b92d-b9b6-4460-a626-6a2402a80ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cd59cf-43e5-4322-a0f0-1156f864dc49",
   "metadata": {},
   "source": [
    "## Please run the script `script/perform_perturbation.py` and then load the results by the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28b7637-54ef-4e91-a664-8b7cd4302a23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "load_data = True\n",
    "data_mode = 'sst'\n",
    "sample_range = range(201)\n",
    "\n",
    "attribution_methods = ['SymbXAI', 'LRP', 'PredDiff','random' ]\n",
    "optimize_parameter = [('minimize', 'removal'), ('maximize', 'removal') , ('minimize', 'generation'), ('maximize', 'generation')]\n",
    "\n",
    "if load_data:\n",
    "    all_output_sequences = {param: {attribution_method: {} for attribution_method in attribution_methods} for param in optimize_parameter }\n",
    "    \n",
    "    for i in sample_range:\n",
    "        if data_mode == 'sst':\n",
    "            file_name = f'/Users/thomasschnake/Downloads/temp/perturbation_results_{data_mode}_{i}.pkl' # 'intermediate_results/perturbation_results_sst.pkl'\n",
    "            try:\n",
    "                with open(file_name, 'rb+') as f:\n",
    "                    # print(f.seek(0))\n",
    "                    output_sequences = pickle.load(f)\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "        elif data_mode in ['imdb']:\n",
    "            output_sequences = {}\n",
    "            for par1, par2 in optimize_parameter:\n",
    "                try:\n",
    "                    file_name = f'/Users/thomasschnake/Downloads/temp/perturbation_results_{data_mode}_{i}_{par1}_{par2}_curves.pkl'\n",
    "                    with open(file_name, 'rb+') as f:\n",
    "                        # print(f.seek(0))\n",
    "                        this_output = pickle.load(f)\n",
    "                        output_sequences.update(this_output)\n",
    "                except:\n",
    "                    # print('skipped', i, par1, par2)\n",
    "                    continue\n",
    "                \n",
    "        # print()        \n",
    "        for attribution_method in attribution_methods:\n",
    "            for param in output_sequences.keys():\n",
    "                all_output_sequences[param][attribution_method].update(output_sequences[param][attribution_method])\n",
    "            \n",
    "\n",
    "for attribution_method in attribution_methods:\n",
    "    for auc_task, perturbation_type in optimize_parameter:\n",
    "        print(attribution_method, auc_task, perturbation_type, '\\t\\t', len(all_output_sequences[(auc_task,perturbation_type)][attribution_method].keys()))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a523649e-3946-46b3-b180-7cb587168698",
   "metadata": {},
   "source": [
    "## Plot the perturbation curves and their integral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c2b63c-a019-47d5-8f5d-6064506ee091",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "import numpy as np\n",
    "def resample_sequence(sequence, k):\n",
    "    n = len(sequence)\n",
    "    x_original = np.linspace(0, 1, n)\n",
    "    x_new = np.linspace(0, 1, k)\n",
    "    \n",
    "    if k < n:\n",
    "        # Downsampling: averaging within bins\n",
    "        new_sequence = []\n",
    "        bin_edges = np.linspace(0, n, k+1)\n",
    "        for i in range(k):\n",
    "            bin_start = int(bin_edges[i])\n",
    "            bin_end = int(bin_edges[i+1])\n",
    "            if bin_end > bin_start:\n",
    "                bin_values = sequence[bin_start:bin_end]\n",
    "                bin_average = np.mean(bin_values)\n",
    "                new_sequence.append(bin_average)\n",
    "            else:\n",
    "                new_sequence.append(sequence[bin_start])\n",
    "        return np.array(new_sequence)\n",
    "    else:\n",
    "        # Upsampling: interpolation\n",
    "        interpolator = interp1d(x_original, sequence, kind='linear')\n",
    "        new_sequence = interpolator(x_new)\n",
    "        return new_sequence\n",
    "\n",
    "text_parser = { 'removal' : 'AURC',\n",
    "                'generation': 'AUGC',\n",
    "                'minimize' : '$\\\\min$',\n",
    "                'maximize' : '$\\\\max$'}\n",
    "\n",
    "grid_resolution = 50 #max(len(sublist) for sublist in all_output_sequences[attribution_method])\n",
    "averages = {param: {} for param in optimize_parameter}\n",
    "\n",
    "for i, attribution_method in enumerate(attribution_methods):\n",
    "    for auc_task, perturbation_type in optimize_parameter:\n",
    "        # find for each sequence a averaged sequence of length grid_resolution\n",
    "        sequences_in_percent = []\n",
    "        for sublist in all_output_sequences[(auc_task, perturbation_type)][attribution_method].values():\n",
    "            sequences_in_percent.append(resample_sequence(sublist[1:-1], grid_resolution))\n",
    "    \n",
    "        # take the mean\n",
    "        averages[(auc_task, perturbation_type)][attribution_method] = np.mean(sequences_in_percent, axis = 0)\n",
    "\n",
    "fig, axs = plt.subplots(1,4, figsize=(20,5))\n",
    "for i, (auc_task, perturbation_type) in enumerate(optimize_parameter):\n",
    "    for attribution_method in attribution_methods:\n",
    "        axs[i].plot(averages[(auc_task, perturbation_type)][attribution_method], label=attribution_method, lw=3)\n",
    "    \n",
    "    axs[i].set_title( text_parser[auc_task] + ' ' + text_parser[perturbation_type] )\n",
    "    axs[i].set_xticks(ticks=[0, .25 * grid_resolution, .5 * grid_resolution, .75 * grid_resolution, grid_resolution],\n",
    "               labels=['0%', '25%', '50%', '75%', '100%'])\n",
    "plt.legend()\n",
    "plt.savefig(f'pics/perturbation_curves_{data_mode}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ece3266-eabd-4741-b079-c1e7e56b3482",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce \n",
    "\n",
    "print( ' & ' + reduce( lambda x,y : x + ' & '  +y, [text_parser[param[0]] + ' ' + text_parser[param[1]] for param in optimize_parameter]) + ' \\\\\\ ')\n",
    "print('\\hline \\hline')\n",
    "for attribution_method in attribution_methods:\n",
    "    outstring = attribution_method\n",
    "    for param in optimize_parameter:\n",
    "        outstring+=  f' & {round(sum(averages[param][attribution_method])/grid_resolution, 2)} '\n",
    "    outstring += ' \\\\\\ '\n",
    "    print(outstring)\n",
    "    print('\\hline')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227faad2-1dba-4c73-97dd-376de87fa25f",
   "metadata": {},
   "source": [
    "# Look at the feature orderings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ed5d98-e4e2-48c2-9e87-67c4a097fef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_mode = 'fer'\n",
    "sample_range = range(201)\n",
    "\n",
    "attribution_methods = ['SymbXAI', 'LRP', 'PredDiff','random' ]\n",
    "optimize_parameter = [('minimize', 'removal'), ('maximize', 'removal') , ('minimize', 'generation'), ('maximize', 'generation')]\n",
    "\n",
    "all_output_orderings = {param: {attribution_method: {} for attribution_method in attribution_methods} for param in optimize_parameter }\n",
    "\n",
    "for i in sample_range:\n",
    "    if data_mode == 'sst':\n",
    "        file_name = f'/Users/thomasschnake/Downloads/temp/perturbation_results_{data_mode}_{i}.pkl' # 'intermediate_results/perturbation_results_sst.pkl'\n",
    "        try:\n",
    "            with open(file_name, 'rb+') as f:\n",
    "                # print(f.seek(0))\n",
    "                output_orderings = pickle.load(f)\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "    elif data_mode in ['imdb', 'fer']:\n",
    "        output_orderings = {}\n",
    "        for par1, par2 in optimize_parameter:\n",
    "            try:\n",
    "                file_name = f'/Users/thomasschnake/Downloads/temp/perturbation_results_{data_mode}_{i}_{par1}_{par2}_orderings.pkl'\n",
    "                with open(file_name, 'rb+') as f:\n",
    "                    # print(f.seek(0))\n",
    "                    this_output = pickle.load(f)\n",
    "                    output_orderings.update(this_output)\n",
    "            except:\n",
    "                # print('skipped', i, par1, par2)\n",
    "                continue\n",
    "            \n",
    "    # print()        \n",
    "    for attribution_method in attribution_methods:\n",
    "        for param in output_orderings.keys():\n",
    "            all_output_orderings[param][attribution_method].update(output_orderings[param][attribution_method])\n",
    "        \n",
    "\n",
    "for attribution_method in attribution_methods:\n",
    "    for auc_task, perturbation_type in optimize_parameter:\n",
    "        print(attribution_method, auc_task, perturbation_type, '\\t\\t', len(all_output_orderings[(auc_task,perturbation_type)][attribution_method].keys()))\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "symbxai",
   "language": "python",
   "name": "symbxai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
