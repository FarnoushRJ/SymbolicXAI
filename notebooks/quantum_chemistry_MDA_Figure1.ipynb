{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "059ce733",
   "metadata": {},
   "source": [
    "# Analyzing the MDA trajectory\n",
    "\n",
    "Particularly, compare the contributions with the coulomb potential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810f379c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de58bf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import schnetpack as sp\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "from copy import copy, deepcopy\n",
    "import networkx as nx\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "import torch, numpy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from symbxai.lrp.symbolic_xai import SchNetSymbXAI\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from numpy import genfromtxt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ccaaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A few global variables\n",
    "atom_names_dict = {1: \"H\", 6: \"C\", 7: \"N\", 8: \"O\", 9: \"F\"}\n",
    "models = {}\n",
    "datasets = {}\n",
    "target_props = {}\n",
    "cutoff = {}\n",
    "kcal2eV_scal=23.060541945329334"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9882c5",
   "metadata": {},
   "source": [
    "# Load MDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baace2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdamodel_file = '../saved_models/mda_schnorb_model_v2/best_model'\n",
    "mdamodel = torch.load(mdamodel_file, map_location=torch.device('cpu'))\n",
    "cutoff['mda'] = mdamodel.representation.cutoff_fn.cutoff.item()\n",
    "# qm9model.do_postprocessing = False\n",
    "models['mda'] = mdamodel\n",
    "\n",
    "target_props['mda'] = 'energy'\n",
    "model= mdamodel\n",
    "# models['qm9'](copy(datasets['mda'][0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cdbabb",
   "metadata": {},
   "source": [
    "# Load the Data - MDA Trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455a065b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ase.io import read\n",
    "\n",
    "from schnetpack.interfaces.ase_interface import AtomsConverter\n",
    "\n",
    "ats = read('data/mda_extracted_88300_88800.xyz', index=\":\")\n",
    "\n",
    "converter = AtomsConverter(neighbor_list=sp.transform.ASENeighborList(cutoff=cutoff['mda']),\n",
    "        device=\"cpu\",\n",
    "        dtype=torch.float32\n",
    "    )\n",
    "\n",
    "mdatraj = [converter(at) for at in ats]\n",
    "\n",
    "datasets['mdatraj'] = mdatraj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e464bdcc",
   "metadata": {},
   "source": [
    "# Load MDA in equilibrium state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b233d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ase.io import read\n",
    "\n",
    "from schnetpack.interfaces.ase_interface import AtomsConverter\n",
    "\n",
    "ats = read('data/equi_mda.extxyz', index=\":\")\n",
    "\n",
    "converter = AtomsConverter(neighbor_list=sp.transform.ASENeighborList(cutoff=cutoff['mda']),\n",
    "        device=\"cpu\",\n",
    "        dtype=torch.float32\n",
    "    )\n",
    "\n",
    "emda = [converter(at) for at in ats]\n",
    "\n",
    "datasets['equi_mda'] = emda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68806409",
   "metadata": {},
   "source": [
    "## Visualize one MDA molecule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09de7629",
   "metadata": {},
   "outputs": [],
   "source": [
    "from symbxai.visualization.qc_utils import vis_mol_2d\n",
    "fig, ax = plt.subplots(figsize=(7,7))\n",
    "sample = datasets['mdatraj'][0]\n",
    "anum, pos = sample['_atomic_numbers'].data.numpy(), sample['_positions'].data.numpy()\n",
    "\n",
    "vis_mol_2d(ax,\n",
    "            anum,\n",
    "            pos,\n",
    "           projdim=0,\n",
    "          with_atom_id=True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2fbbd0-8cce-464d-94aa-aad07f64169a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_const_approx(vals):\n",
    "    osplit_id, ovleft, ovright = 0, float('inf'), float('inf')\n",
    "    for split_id in range(1,len(vals)-1):\n",
    "        left, right = vals[:split_id], vals[split_id:]\n",
    "        vleft, vright = len(left)*numpy.var(left), len(right)*numpy.var(right)\n",
    "\n",
    "        if ovleft+ovright > vleft+vright:\n",
    "            # found new optimum\n",
    "            osplit_id, ovleft, ovright = split_id, vleft, vright\n",
    "            \n",
    "    return osplit_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35dab9f-f61c-4256-b9bf-16f1d9956707",
   "metadata": {},
   "source": [
    "## Total energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101e3af3-098a-44cc-8e52-4accbdb297ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_outs = [model(copy(sample))['energy'].detach().numpy() for sample in mdatraj ]\n",
    "plt.figure(figsize=(4,2))\n",
    "plt.plot(all_outs, lw=12, color='black')\n",
    "plt.ylim(sum(all_outs)/len(all_outs) -1, sum(all_outs)/len(all_outs) +1)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "# plt.savefig('pics/qc_prediction_change_fig1.svg', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd190929-846a-4556-9df1-7ed73d0e14dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from symbxai.visualization.utils import vis_barh_query\n",
    "osplit_id = find_const_approx(all_outs)\n",
    "split_dist = abs(np.mean(all_outs[:osplit_id]) - np.mean(all_outs[osplit_id:]))\n",
    "vis_barh_query({'energy':split_dist}, xlim=(0,1),filename=None\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d90450d-5bc4-421f-a505-72c0bf686c65",
   "metadata": {},
   "source": [
    "# Experiment 1 - visualize all first order contributions (classic XAI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61a8f58",
   "metadata": {},
   "source": [
    "# node contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bf6541-12ab-4fc1-b9e9-9c76e419bd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stop_top = 3\n",
    "\n",
    "model_mode = 'mda'\n",
    "model = models[model_mode]\n",
    "gamma = .0\n",
    "\n",
    "ida2atnnum_str = lambda ida: atom_names_dict[sample['_atomic_numbers'][ida].item()]\n",
    "\n",
    "\n",
    "all_lrp_contr = []\n",
    "for sample in mdatraj:\n",
    "    explainer = SchNetSymbXAI(copy(sample),\n",
    "                                      models[model_mode], \n",
    "                                      target_props[model_mode], \n",
    "                                      gamma = gamma)\n",
    "    all_lrp_contr.append(explainer.node_relevance())\n",
    "\n",
    "all_lrp_contr = torch.stack(all_lrp_contr)\n",
    "\n",
    "node_cp_dist ={}\n",
    "for i in range(all_lrp_contr.shape[1]):\n",
    "    rels = all_lrp_contr[:,i].numpy()\n",
    "    osplit_id = find_const_approx(rels)\n",
    "    split_dist = abs(np.mean(rels[:osplit_id]) - np.mean(rels[osplit_id:]))\n",
    "    node_cp_dist[ida2atnnum_str(i) + f'$_{i}$'] = split_dist \n",
    "    \n",
    "print('Distance of the constant approx')\n",
    "node_cp_dist = dict(sorted(node_cp_dist.items(), key=lambda item: item[1], reverse=True))\n",
    "vis_barh_query({key:val for i, (key,val) in enumerate(node_cp_dist.items()) if i < stop_top}, xlim=(0,1),\n",
    "              filename=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954dde02-c201-4a0f-8c61-a75c3ed64b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "topkeys = [key for num, (key,val) in enumerate(node_cp_dist.items()) if num<stop_top]\n",
    "for i in range(all_lrp_contr.shape[1]):\n",
    "    \n",
    "    if ida2atnnum_str(i) + f'$_{i}$' in topkeys:\n",
    "        fig, ax = plt.subplots(1,1, figsize=(4,2))\n",
    "        print(ida2atnnum_str(i) + f'$_{i}$')\n",
    "        plt.plot(all_lrp_contr[:,i], lw=12, color='black' ) #, label= ida2atnnum_str(i) + f'$_{i}$')\n",
    "        margin = (2 - (max(all_lrp_contr[:,i]) - min(all_lrp_contr[:,i])))/2\n",
    "        plt.ylim([min(all_lrp_contr[:,i])-margin, max(all_lrp_contr[:,i])+margin])\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        # plt.savefig(f'pics/qc_node_change_fig1_{i}.svg', transparent=True)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fd0c2b-0ba6-4983-846a-3db88f266f76",
   "metadata": {},
   "source": [
    "# Experiment 2 - Find the reaction variable using SymbXAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d882d1e9-e945-4beb-9935-2447414df782",
   "metadata": {},
   "source": [
    "## Step 1: Compute all Harsanyi Dividends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9843408-4f43-4d6a-8058-e51cebd94ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from symbxai.utils import powerset\n",
    "\n",
    "max_order = 1\n",
    "all_hars_div = []\n",
    "all_sets = powerset(range(9), K=max_order)\n",
    "\n",
    "for sample in tqdm(mdatraj):\n",
    "    explainer = SchNetSymbXAI(copy(sample),\n",
    "                              models[model_mode], \n",
    "                              target_props[model_mode], \n",
    "                              gamma = gamma)\n",
    "    \n",
    "    hars_div = []\n",
    "    for S in all_sets:\n",
    "        hars_div.append(explainer.harsanyi_div(S))\n",
    "    all_hars_div.append(torch.tensor(hars_div))\n",
    "all_hars_div = torch.stack(all_hars_div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5e16e9-1f37-4898-ac46-8ff881b071cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# pickle.dump(all_hars_div, open(f'intermediate_results/query_search_algo/hars_mda_traj_max_order{max_order}.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd601e9-d60c-4d2f-95a6-09b6b700ed19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from symbxai.query_search.utils import setup_queries\n",
    "\n",
    "max_setsize = 1\n",
    "max_and_order = 1\n",
    "max_indexdist = float('inf') # ist aber egal mit max_setsize = 1\n",
    "query_mode = 'conj. disj. reasonably mixed' #'conj. disj. (neg. disj.) reasonably mixed'\n",
    "tokens = [ida2atnnum_str(i) + f'{i}' for i in explainer.node_domain]\n",
    "\n",
    "all_queries = setup_queries(explainer.node_domain, \n",
    "                                    tokens,\n",
    "                                    max_and_order, \n",
    "                                    max_setsize=max_setsize, \n",
    "                                    max_indexdist=max_indexdist, \n",
    "                                    mode=query_mode,\n",
    "                                    repres_style='Latex')\n",
    "\n",
    "all_attributions = []\n",
    "for query in all_queries:\n",
    "    all_attr_per_query = []\n",
    "    for hars_div in all_hars_div:\n",
    "        all_attr_per_query.append( sum([hars_div[i] for i, S in enumerate(all_sets) if query(S)]))\n",
    "    all_attributions.append(torch.tensor(all_attr_per_query))\n",
    "        \n",
    "all_attributions = torch.stack(all_attributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f544c4b1-a742-4cf9-86bc-31265286ff8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_top =3\n",
    "query_cp_dist = {}\n",
    "for i in range(all_attributions.shape[0]):\n",
    "    query = all_queries[i]\n",
    "    rels = all_attributions[i].numpy()\n",
    "    osplit_id = find_const_approx(rels)\n",
    "    split_dist = abs(np.mean(rels[:osplit_id]) - np.mean(rels[osplit_id:]))\n",
    "    query_cp_dist[query.str_rep] = split_dist\n",
    "\n",
    "query_cp_dist = dict(sorted(query_cp_dist.items(), key=lambda item: abs(item[1]), reverse=True))\n",
    "top_query_dists = {key:val for i,(key,val) in enumerate(query_cp_dist.items()) if i < stop_top}\n",
    "vis_barh_query(top_query_dists, xlim=(0,1),\n",
    "              filename=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae769de4-11ad-40e7-832b-206f88dbfcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(all_attributions.shape[0]):\n",
    "    query = all_queries[i]\n",
    "    if query.str_rep in top_query_dists.keys():\n",
    "        fig, ax = plt.subplots(1,1, figsize=(4,2))\n",
    "        print(query.str_rep)\n",
    "        plt.plot(all_attributions[i], lw=12, color='black' ) #, label= ida2atnnum_str(i) + f'$_{i}$')\n",
    "        margin = (2 - (max(all_attributions[i]) - min(all_attributions[i])))/2\n",
    "        plt.ylim([min(all_attributions[i])-margin, max(all_attributions[i])+margin])\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        # plt.legend()\n",
    "        # plt.savefig(f'pics/qc_query_change_fig1_{query.str_rep}.svg', transparent=True)\n",
    "        plt.show()\n",
    "        \n",
    "        # plt.plot(all_attributions[i], label=query.str_rep)\n",
    "    \n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ae4fc0-a712-4694-bc57-8a21ed9b79bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dists = []\n",
    "atom_pairs = []\n",
    "for i in range(sample['_n_atoms']):\n",
    "    for j in range(sample['_n_atoms']):\n",
    "        if i<j: atom_pairs.append((i,j))\n",
    "\n",
    "for sample in mdatraj:\n",
    "    dists = torch.cdist(sample['_positions'],sample['_positions'])\n",
    "    pairwise_dists = torch.tensor([dists[i,j] for i,j in atom_pairs])\n",
    "    all_dists.append(pairwise_dists)\n",
    "\n",
    "all_dists = torch.stack(all_dists)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef558883-a0af-4794-9ed7-7fcf98e0744c",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_top =10\n",
    "apair_dist_cp_dist = {}\n",
    "for i in range(all_dists.shape[1]):\n",
    "    rels = all_dists[:,i].numpy()\n",
    "    a1, a2 = atom_pairs[i]\n",
    "    osplit_id = find_const_approx(rels)\n",
    "    split_dist = abs(np.mean(rels[:osplit_id]) - np.mean(rels[osplit_id:]))\n",
    "    str_rep = ida2atnnum_str(a1) + f'$_{a1}$ - '+ ida2atnnum_str(a2)+f'$_{a2}$' \n",
    "    apair_dist_cp_dist[ str_rep ] = split_dist\n",
    "\n",
    "apair_dist_cp_dist = dict(sorted(apair_dist_cp_dist.items(), key=lambda item: item[1], reverse=True))\n",
    "top_dist_dists = {key:val for i,(key,val) in enumerate(apair_dist_cp_dist.items()) if i < show_top}\n",
    "vis_barh_query(top_dist_dists)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "symbxai",
   "language": "python",
   "name": "symbxai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
